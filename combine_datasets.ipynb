{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPd9hZXtC1RB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYulutFq3U74",
    "outputId": "845fb976-5aff-4f98-f200-118dea518ef5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46332\\1305820514.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Loading and preprocessing the Twitter Dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/training.1600000.processed.noemoticon.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"date\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"flag\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"user\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ansi\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"date\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"flag\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"user\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Loading and preprocessing the Twitter Dataset.\n",
    "\n",
    "df = pd.read_csv(\"../data/training.1600000.processed.noemoticon.csv\", names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"], encoding=\"ansi\")\n",
    "df[\"target\"] = np.where(df[\"target\"] != 4, 0, 1)\n",
    "df = df.drop(columns = [\"id\", \"date\", \"flag\", \"user\"], axis = 1)\n",
    "df = df.rename(columns={'target': 'response'})\n",
    "df = df.rename(columns={'text': 'instruction'})\n",
    "\n",
    "# Converting the labels\n",
    "df['response'] = df['response'].replace({0: 'negative', 1: 'positive'})\n",
    "df = df[['instruction', 'response']]\n",
    "rows_to_drop = int(0.01 * len(df))\n",
    "df = df.sample(n=rows_to_drop, random_state=42, replace=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             instruction  response\n",
      "0      According to Gran , the company has no plans t...   neutral\n",
      "1      Technopolis plans to develop in stages an area...   neutral\n",
      "2      The international electronic industry company ...  negative\n",
      "3      With the new production plant the company woul...  positive\n",
      "4      According to the company 's updated strategy f...  positive\n",
      "...                                                  ...       ...\n",
      "14775  Operating result for the 12-month period decre...  negative\n",
      "14776  HELSINKI Thomson Financial - Shares in Cargote...  negative\n",
      "14777  LONDON MarketWatch -- Share prices ended lower...  negative\n",
      "14778  Operating profit fell to EUR 35.4 mn from EUR ...  negative\n",
      "14779  Sales in Finland decreased by 10.5 % in Januar...  negative\n",
      "\n",
      "[14780 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Loading and preprocessing the Financial Phrasebank Dataset.\n",
    "\n",
    "financial_df_50 = pd.read_csv(\"../data/Sentences_50Agree.txt\", names=[\"instruction\",\"response\"], encoding=\"windows-1252\", header=None, delimiter=\"@\")\n",
    "financial_df_66 = pd.read_csv(\"../data/Sentences_66Agree.txt\", names=[\"instruction\",\"response\"], encoding=\"windows-1252\", header=None, delimiter=\"@\")\n",
    "financial_df_75 = pd.read_csv(\"../data/Sentences_75Agree.txt\", names=[\"instruction\",\"response\"], encoding=\"windows-1252\", header=None, delimiter=\"@\")\n",
    "financial_df_100 = pd.read_csv(\"../data/Sentences_AllAgree.txt\", names=[\"instruction\",\"response\"], encoding=\"windows-1252\", header=None, delimiter=\"@\")\n",
    "\n",
    "financial_df_50 = pd.concat([financial_df_50, financial_df_66], ignore_index=True)\n",
    "financial_df_50 = pd.concat([financial_df_50, financial_df_75], ignore_index=True)\n",
    "financial_df_50 = pd.concat([financial_df_50, financial_df_100], ignore_index=True)\n",
    "\n",
    "print(financial_df_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                instruction  response\n",
      "42125.0   Had to add this, cause it's sooo good!\\n#ChatG...   neutral\n",
      "116753.0                Get on the ChatGPT wave. Itâ€™s real.  negative\n",
      "187971.0  ChatGPT for Google: A Browser Extension to Dis...  negative\n",
      "115077.0  chatgpt is legit overloaded right now, interes...   neutral\n",
      "177607.0  When I started, I thought coding was the most ...  positive\n",
      "...                                                     ...       ...\n",
      "41680.0   StackOverflow pollution considered harmful.\\n\\...  negative\n",
      "53639.0   The first question I ask ChatGPT... https://t....  negative\n",
      "218707.0  How The ChatGPT Watermark Works And Why It Cou...  negative\n",
      "218464.0  The more I test ChatGPT and Jasper Chat I thin...  positive\n",
      "66427.0   \"The Brilliance and Weirdness of ChatGPT\" by K...   neutral\n",
      "\n",
      "[17543 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Loading and preprocessing the Twitter Dataset.\n",
    "\n",
    "chatgpt_df = pd.read_csv(\"../data/file.csv\", names=[\"instruction\",\"response\"])\n",
    "chatgpt_df['response'] = chatgpt_df['response'].replace({'bad': 'negative', 'good': 'positive'})\n",
    "\n",
    "rows_to_drop = int(0.08 * len(chatgpt_df))\n",
    "chatgpt_df = chatgpt_df.sample(n=rows_to_drop, random_state=42, replace=False)\n",
    "print(chatgpt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             instruction  response\n",
      "0      According to Gran , the company has no plans t...   neutral\n",
      "1      Technopolis plans to develop in stages an area...   neutral\n",
      "2      The international electronic industry company ...  negative\n",
      "3      With the new production plant the company woul...  positive\n",
      "4      According to the company 's updated strategy f...  positive\n",
      "...                                                  ...       ...\n",
      "48318                        On my way to my last exam.   positive\n",
      "48319  so, you should go check this guy out, he's pre...  positive\n",
      "48320  enjoyed a wonderful weekend with my princess &...  negative\n",
      "48321  got a sore throat  well its not really sore, j...  negative\n",
      "48322  Just uploading tracks off the new album 'Islan...  positive\n",
      "\n",
      "[48323 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Combined Dataset:\n",
    "\n",
    "financial_df_50 = pd.concat([financial_df_50, chatgpt_df], ignore_index=True)\n",
    "financial_df_50 = pd.concat([financial_df_50, df], ignore_index=True)\n",
    "print(financial_df_50)\n",
    "\n",
    "# Shuffle dataset:\n",
    "shuffled_df = financial_df_50.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change labels:\n",
    "shuffled_df['response'] = shuffled_df['response'].replace({'negative' : 0, 'neutral': 1, 'positive' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             instruction  response\n",
      "37428  @missdaisymusic LOL thanks for that! You shoul...         2\n",
      "29221  Excellent #foodforthought.\\nðŸ‘‰What if much of t...         2\n",
      "3180   The combined value of the planned investments ...         1\n",
      "16572  Popular coding forum Stack Overflow temporaril...         2\n",
      "6939   Ixonos estimates that it will hire 20 speciali...         2\n",
      "...                                                  ...       ...\n",
      "11284  The employee negotiations are to address measu...         1\n",
      "44732                          HELLOOOOOOOOO EVERYONE!!          2\n",
      "38158  @MeaganOnlineNet Thanks girl  .. Glad you're b...         2\n",
      "860    ( ADP News ) - Oct 1 , 2008 - Finnish consulti...         2\n",
      "15795  The power of ChatGPT is incredible. I asked it...         2\n",
      "\n",
      "[48323 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final dataset:\n",
    "print(shuffled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save combined dataset as a CSV.\n",
    "shuffled_df.to_csv('combined_small_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
